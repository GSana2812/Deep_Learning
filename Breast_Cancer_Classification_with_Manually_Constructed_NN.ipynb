{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will include an analysis of the Breast Classification Dataset, now consisting in a manually constructed Neural Networks with the help of Pytorch. "
      ],
      "metadata": {
        "id": "0zM4C9CiO-K3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Packages"
      ],
      "metadata": {
        "id": "j-T9N8UhPNs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.datasets\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "nn-pZ_oFPRZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "x5PE0fRwPSzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bc_df = sklearn.datasets.load_breast_cancer() #loading the dataset; its in the form of a dictionary"
      ],
      "metadata": {
        "id": "TWLfXr-kPY6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(bc_df.data, columns = bc_df.feature_names) #converting it to a proper dataframe"
      ],
      "metadata": {
        "id": "bp7ZnuWnPbJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "TQJtSpAjPcrl",
        "outputId": "e7b8d700-2abe-4620-92b0-32aa4e850fe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0        17.99         10.38          122.80     1001.0          0.11840   \n",
              "1        20.57         17.77          132.90     1326.0          0.08474   \n",
              "2        19.69         21.25          130.00     1203.0          0.10960   \n",
              "3        11.42         20.38           77.58      386.1          0.14250   \n",
              "4        20.29         14.34          135.10     1297.0          0.10030   \n",
              "\n",
              "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0           0.27760          0.3001              0.14710         0.2419   \n",
              "1           0.07864          0.0869              0.07017         0.1812   \n",
              "2           0.15990          0.1974              0.12790         0.2069   \n",
              "3           0.28390          0.2414              0.10520         0.2597   \n",
              "4           0.13280          0.1980              0.10430         0.1809   \n",
              "\n",
              "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
              "0                 0.07871  ...         25.38          17.33           184.60   \n",
              "1                 0.05667  ...         24.99          23.41           158.80   \n",
              "2                 0.05999  ...         23.57          25.53           152.50   \n",
              "3                 0.09744  ...         14.91          26.50            98.87   \n",
              "4                 0.05883  ...         22.54          16.67           152.20   \n",
              "\n",
              "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
              "0      2019.0            0.1622             0.6656           0.7119   \n",
              "1      1956.0            0.1238             0.1866           0.2416   \n",
              "2      1709.0            0.1444             0.4245           0.4504   \n",
              "3       567.7            0.2098             0.8663           0.6869   \n",
              "4      1575.0            0.1374             0.2050           0.4000   \n",
              "\n",
              "   worst concave points  worst symmetry  worst fractal dimension  \n",
              "0                0.2654          0.4601                  0.11890  \n",
              "1                0.1860          0.2750                  0.08902  \n",
              "2                0.2430          0.3613                  0.08758  \n",
              "3                0.2575          0.6638                  0.17300  \n",
              "4                0.1625          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ce0f805-eeab-4b3a-9e10-e1c88811f2fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ce0f805-eeab-4b3a-9e10-e1c88811f2fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ce0f805-eeab-4b3a-9e10-e1c88811f2fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ce0f805-eeab-4b3a-9e10-e1c88811f2fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adding the target variable to the df\n",
        "df['label'] = bc_df.target"
      ],
      "metadata": {
        "id": "jFUFY91DPej4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info() #no missing values so far"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vlRMkryPhTT",
        "outputId": "18dc800c-7beb-417f-ee2c-90712062138b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean radius              569 non-null    float64\n",
            " 1   mean texture             569 non-null    float64\n",
            " 2   mean perimeter           569 non-null    float64\n",
            " 3   mean area                569 non-null    float64\n",
            " 4   mean smoothness          569 non-null    float64\n",
            " 5   mean compactness         569 non-null    float64\n",
            " 6   mean concavity           569 non-null    float64\n",
            " 7   mean concave points      569 non-null    float64\n",
            " 8   mean symmetry            569 non-null    float64\n",
            " 9   mean fractal dimension   569 non-null    float64\n",
            " 10  radius error             569 non-null    float64\n",
            " 11  texture error            569 non-null    float64\n",
            " 12  perimeter error          569 non-null    float64\n",
            " 13  area error               569 non-null    float64\n",
            " 14  smoothness error         569 non-null    float64\n",
            " 15  compactness error        569 non-null    float64\n",
            " 16  concavity error          569 non-null    float64\n",
            " 17  concave points error     569 non-null    float64\n",
            " 18  symmetry error           569 non-null    float64\n",
            " 19  fractal dimension error  569 non-null    float64\n",
            " 20  worst radius             569 non-null    float64\n",
            " 21  worst texture            569 non-null    float64\n",
            " 22  worst perimeter          569 non-null    float64\n",
            " 23  worst area               569 non-null    float64\n",
            " 24  worst smoothness         569 non-null    float64\n",
            " 25  worst compactness        569 non-null    float64\n",
            " 26  worst concavity          569 non-null    float64\n",
            " 27  worst concave points     569 non-null    float64\n",
            " 28  worst symmetry           569 non-null    float64\n",
            " 29  worst fractal dimension  569 non-null    float64\n",
            " 30  label                    569 non-null    int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 137.9 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split data into features and targets"
      ],
      "metadata": {
        "id": "TUhqRmsSPinA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns = ['label'], axis = 1)\n",
        "y = df['label']"
      ],
      "metadata": {
        "id": "d5QmPb52Po2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "I3PwMFoyPzhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Standardize the data"
      ],
      "metadata": {
        "id": "_KJvovpMP4vB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "mE5uE69RP7AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "standard_scaler = StandardScaler()\n",
        "\n",
        "X_train_std = standard_scaler.fit_transform(X_train)\n",
        "X_test_std = standard_scaler.fit_transform(X_test)\n",
        "X_std = standard_scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "Up7VZPEWP9d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert dataframes into numpy arrays\n",
        "y_train_array = y_train.to_numpy()\n",
        "y_test_array = y_test.to_numpy()\n",
        "y_array = y.to_numpy()"
      ],
      "metadata": {
        "id": "wWOppICOUlT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "yh5BV5gXP_9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train_std.shape[1]\n",
        "hidden_size = 20\n",
        "output_size = 2 #applying softmax "
      ],
      "metadata": {
        "id": "aNW5GaeYQW_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create the class Data to convert the dataframes of our training and test sets into torch tensors. Also we will divide our sets into batches of 32. "
      ],
      "metadata": {
        "id": "TGPXQLLRQqCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert the numpy arrays into tensors\n",
        "\n",
        "y_train_list = list(y_train_array)\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.from_numpy(X_std.astype(np.float32))\n",
        "        self.y = torch.from_numpy(y_array.astype(np.float32))\n",
        "        self.lengths = self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "train_dataset = MyDataset(X_train_std, y_train_array)\n",
        "test_dataset = MyDataset(X_test_std, y_test_array)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = True)\n",
        "\n",
        "'''for batch, (X, y) in enumerate(loader):\n",
        "    print(\"Batch: \",[batch+1])\n",
        "    print(\"X shape: \", X.shape)\n",
        "    print(\"y shape: \",y.shape)\n",
        "    break'''\n",
        "\n",
        "#number of batches\n",
        "print(len(train_loader))\n",
        "\n",
        "#batch size\n",
        "for batch_inputs, batch_outputs in train_loader:\n",
        "  print(len(batch_inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWQXx4srTfyp",
        "outputId": "12bb2837-2f1c-408f-cbba-f89dba621e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "64\n",
            "64\n",
            "64\n",
            "64\n",
            "64\n",
            "64\n",
            "64\n",
            "64\n",
            "57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network Implementation"
      ],
      "metadata": {
        "id": "qwgL-whsb47K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  \n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "\n",
        "    #Initializing the units\n",
        "    self.input_size = input_size #number of neurons in input layer\n",
        "    self.hidden_size = hidden_size #number of neurons in the hidden layer\n",
        "    self.output_size = output_size\n",
        "\n",
        "\n",
        "    #Defining the layers\n",
        "    self.layer_1 = nn.Linear(input_size, hidden_size)\n",
        "\n",
        "    #Implementing relu function which will be applied to first layer\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    #initializing the weights of the neural network using the Kaiming uniform method\n",
        "    nn.init.kaiming_uniform(self.layer_1.weight, nonlinearity = \"relu\")\n",
        "\n",
        "    #Defining the output layer\n",
        "    self.layer_2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    #Implementing sigmoid function which will be applied to the output layer\n",
        "    self.softmax = nn.Softmax()\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    layer_1 = self.layer_1(x)\n",
        "    relu = self.relu(layer_1)\n",
        "    layer_2 = self.layer_2(relu)\n",
        "    output = self.softmax(layer_2)\n",
        "    \n",
        "    return output"
      ],
      "metadata": {
        "id": "VlUkfLPxdC7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork(input_size, hidden_size, output_size)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUAeqgVYe4yO",
        "outputId": "55c09f4d-05bb-4a38-dfd1-a9af93cf9b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (layer_1): Linear(in_features=30, out_features=20, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (layer_2): Linear(in_features=20, out_features=2, bias=True)\n",
            "  (softmax): Softmax(dim=None)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-8f844e9b8366>:20: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "  nn.init.kaiming_uniform(self.layer_1.weight, nonlinearity = \"relu\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimization"
      ],
      "metadata": {
        "id": "42uTggSwfb6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "vmjuJIg2f_vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To calculate the model, we must define a loss function to calculate the gradients and an optimizer to update the parameters. We are going to use Binary Cross Entropy with Stochastic Gradient Descent and a learning rate of 0.001."
      ],
      "metadata": {
        "id": "M4yFvmMigOIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializing learning rate\n",
        "learning_rate = 0.0001\n",
        "\n",
        "#Initializing the Stochasting Gradient Descent, which will update the weights\n",
        "stochastic = optim.Adam(model.parameters(), lr = learning_rate)\n"
      ],
      "metadata": {
        "id": "Bx-B91rNgfOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AGvHfk3JlUFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize the number of epochs\n",
        "'''epochs = 10\n",
        "loss_values = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    #Set the gradients to zero\n",
        "    stochastic.zero_grad()\n",
        "\n",
        "    #Predict the model\n",
        "    y_pred = model(X_train_tensor)\n",
        "  \n",
        "    #Get the loss\n",
        "    y_train_tensor = y_train_tensor.long()\n",
        "\n",
        "    loss = loss_function(y_pred, y_train_tensor)\n",
        "\n",
        "    #Get the stats\n",
        "    print(f\"Epoch {epoch}: traing loss: {loss}\")\n",
        "\n",
        "    #Compute the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    #Take a step to optimize the weights\n",
        "    stochastic.step()\n",
        "\n",
        "print(y_pred.shape)'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "rGy6FGa7hDvY",
        "outputId": "4d8b3b24-4272-46d8-f364-ba07129430a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'epochs = 10\\nloss_values = []\\n\\nfor epoch in range(epochs):\\n\\n    #Set the gradients to zero\\n    stochastic.zero_grad()\\n\\n    #Predict the model\\n    y_pred = model(X_train_tensor)\\n  \\n    #Get the loss\\n    y_train_tensor = y_train_tensor.long()\\n\\n    loss = loss_function(y_pred, y_train_tensor)\\n\\n    #Get the stats\\n    print(f\"Epoch {epoch}: traing loss: {loss}\")\\n\\n    #Compute the gradients\\n    loss.backward()\\n\\n    #Take a step to optimize the weights\\n    stochastic.step()\\n\\nprint(y_pred.shape)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define a loss function, which computes to cross entropy loss\n",
        "def loss_function(batch_outputs, batch_labels):   \n",
        "\n",
        "    batch_lengths = np.array([9,64,64,64,64,64,64,57]) #size of batches\n",
        "    # Calculate the loss for the whole batch\n",
        "    cross_entropy = nn.CrossEntropyLoss()\n",
        "    loss = cross_entropy(batch_outputs, batch_labels.long())\n",
        "\n",
        "    # Rescale the loss\n",
        "    loss = loss / np.sum(batch_lengths)\n",
        "\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "fbbFo-SHk5TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that will be called in every epoch\n",
        "def train_epoch(loss_function, optimizer, model, loader):\n",
        "  \n",
        "  # Keep track of the total loss for the batch\n",
        "  total_loss = 0\n",
        "  total_loss = 0\n",
        "  correct_predictions = 0\n",
        "  total_samples = 0\n",
        "\n",
        "\n",
        "  for X, y in train_loader:\n",
        "    # Clear the gradients\n",
        "    optimizer.zero_grad()\n",
        "    # Run a forward pass\n",
        "    pred = model.forward(X)\n",
        "    # Compute the batch loss\n",
        "    loss = loss_function(pred, y)\n",
        "    # Calculate the gradients\n",
        "    loss.backward()\n",
        "    # Update the parameteres\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    correct_predictions += (pred.argmax(dim=1) == y).sum().item()\n",
        "    total_samples += y.size(0)\n",
        "\n",
        "    accuracy = (correct_predictions / total_samples) * 100\n",
        "\n",
        "\n",
        "  return total_loss, accuracy\n",
        "\n",
        "\n",
        "# Function containing our main training loop\n",
        "def train(loss_function, optimizer, model, loader, num_epochs=10000):\n",
        "\n",
        "  # Iterate through each epoch and call our train_epoch function\n",
        "  for epoch in range(num_epochs):\n",
        "    epoch_loss, accuracy = train_epoch(loss_function, optimizer, model, loader)\n",
        "    #if epoch % 100 == 0: print(epoch_loss)\n",
        "    print(\"Epoch: \",epoch,\" training loss: \",epoch_loss, \"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "id": "gt7vkd6QupwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating loss"
      ],
      "metadata": {
        "id": "efi6JTO2xJEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 15\n",
        "train(loss_function, stochastic, model, train_loader, num_epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zseHVpsvuqc1",
        "outputId": "d5286be2-cc02-49fe-b514-b24bfcb078c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-8f844e9b8366>:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = self.softmax(layer_2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0  training loss:  0.01119312981609255 Accuracy:  90.15817223198594\n",
            "Epoch:  1  training loss:  0.011118452181108296 Accuracy:  90.50966608084359\n",
            "Epoch:  2  training loss:  0.011041403515264392 Accuracy:  90.68541300527241\n",
            "Epoch:  3  training loss:  0.01096855802461505 Accuracy:  91.03690685413005\n",
            "Epoch:  4  training loss:  0.010895174113102257 Accuracy:  91.56414762741653\n",
            "Epoch:  5  training loss:  0.010820519528351724 Accuracy:  91.91564147627417\n",
            "Epoch:  6  training loss:  0.01075369876343757 Accuracy:  92.09138840070298\n",
            "Epoch:  7  training loss:  0.01067732262890786 Accuracy:  92.2671353251318\n",
            "Epoch:  8  training loss:  0.010608390788547695 Accuracy:  92.44288224956063\n",
            "Epoch:  9  training loss:  0.010545849218033254 Accuracy:  92.61862917398945\n",
            "Epoch:  10  training loss:  0.010479917051270604 Accuracy:  92.79437609841827\n",
            "Epoch:  11  training loss:  0.010414323769509792 Accuracy:  93.32161687170475\n",
            "Epoch:  12  training loss:  0.010348358773626387 Accuracy:  93.67311072056239\n",
            "Epoch:  13  training loss:  0.010283076902851462 Accuracy:  93.84885764499121\n",
            "Epoch:  14  training loss:  0.010226116515696049 Accuracy:  93.84885764499121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b07PCOKT4wL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mhCJgnVgH8a-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}